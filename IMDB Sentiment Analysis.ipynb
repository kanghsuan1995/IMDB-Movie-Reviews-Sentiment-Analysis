{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read the training data in the folder\n",
    "positive_com = glob.glob(r'C:\\Users\\kangh\\Desktop\\TakeHome - 1 - NLP\\TakeHome - 1 - NLP\\datasets\\Train\\pos\\*.txt')\n",
    "\n",
    "negative_com = glob.glob(r'C:\\Users\\kangh\\Desktop\\TakeHome - 1 - NLP\\TakeHome - 1 - NLP\\datasets\\Train\\neg\\*.txt')\n",
    "\n",
    "pos_list = []\n",
    "\n",
    "for i in positive_com:\n",
    "    file = open(i,'r',encoding=\"ISO-8859-1\")\n",
    "    str_1 = file.readline()\n",
    "    pos_list.append(str_1)\n",
    "    \n",
    "neg_list = []\n",
    "for i in negative_com:\n",
    "    file = open(i,'r',encoding=\"ISO-8859-1\")\n",
    "    str_2 = file.readline()\n",
    "    neg_list.append(str_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Turn the read training data into a dataframe\n",
    "##Set 1 as positive and -1 as negative\n",
    "df_positive = pd.DataFrame()\n",
    "\n",
    "df_positive['comment'] = pos_list\n",
    "df_positive['classification'] = 1\n",
    "df_negative = pd.DataFrame()\n",
    "df_negative['comment'] = neg_list\n",
    "df_negative['classification'] = -1\n",
    "\n",
    "entire_df = pd.concat([df_positive,df_negative], axis = 0)\n",
    "entire_df.index=(range(25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##add the ratio of the punctuation in the sentence as another new feature\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = ps = nltk.PorterStemmer()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "##add the length of the sentence as a new feature\n",
    "entire_df['LENGTH'] = entire_df['comment'].apply(lambda x:len(x) - x.count(' '))\n",
    "\n",
    "\n",
    "##define a function that count the punctuation in the sentence and calculate the ratio over the sentence\n",
    "def count_punc(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return 100*round(count/(len(text)-text.count(' ')),3)\n",
    "\n",
    "##add the ratio of the punctuation in the sentence as another new feature\n",
    "entire_df['punctuation%'] = entire_df['comment'].apply(lambda x:count_punc(x))\n",
    "\n",
    "##define a function that remove '<br />' in the sentence\n",
    "##remove the punctuation\n",
    "##tokenize\n",
    "##PorterStemmer\n",
    "def clean_text(text):\n",
    "    text = re.sub(\"<br />\",'',text)\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+',text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "##Use Tfidf Vectorizer with the function clean_text as the analyzer\n",
    "Tfidf_vect = TfidfVectorizer(analyzer = clean_text)\n",
    "x_count = Tfidf_vect.fit_transform(entire_df['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since the dataset is too large for my computer to run, I turn the processed data into a csr matrix,\n",
    "##therefore my computer would be able to run it. \n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "sparse_dataset = csr_matrix(x_count)\n",
    "s = entire_df[['LENGTH','punctuation%']]\n",
    "sparse_dataset_length_punc = csr_matrix(s)\n",
    "combined_sparse_dataset = hstack((sparse_dataset_length_punc,sparse_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3694, 0.3784, 0.7396, 0.5964, 0.6136])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "rf = RandomForestClassifier(n_jobs = 2)\n",
    "k_fold = KFold(n_splits = 5)\n",
    "cross_val_score(rf,combined_sparse_dataset,entire_df['classification'],cv = k_fold, scoring = 'accuracy',n_jobs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import test data from the test folder\n",
    "positive_com_test = glob.glob(r'C:\\Users\\kangh\\Desktop\\TakeHome - 1 - NLP\\TakeHome - 1 - NLP\\datasets\\Test\\pos\\*.txt')\n",
    "\n",
    "negative_com_test = glob.glob(r'C:\\Users\\kangh\\Desktop\\TakeHome - 1 - NLP\\TakeHome - 1 - NLP\\datasets\\Test\\neg\\*.txt')\n",
    "\n",
    "pos_list_test = []\n",
    "\n",
    "for i in positive_com_test:\n",
    "    file = open(i,'r',encoding=\"ISO-8859-1\")\n",
    "    str_1 = file.readline()\n",
    "    pos_list_test.append(str_1)\n",
    "    \n",
    "neg_list_test = []\n",
    "\n",
    "for i in negative_com_test:\n",
    "    file = open(i,'r',encoding=\"ISO-8859-1\")\n",
    "    str_2 = file.readline()\n",
    "    neg_list_test.append(str_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##turn the read test data into a dataframe\n",
    "df_positive_test = pd.DataFrame()\n",
    "\n",
    "df_positive_test['comment'] = pos_list_test\n",
    "df_positive_test['classification'] = 1\n",
    "\n",
    "df_negative_test = pd.DataFrame()\n",
    "df_negative_test['comment'] = neg_list_test\n",
    "df_negative_test['classification'] = -1\n",
    "\n",
    "entire_df_test = pd.concat([df_positive_test,df_negative_test], axis = 0)\n",
    "\n",
    "entire_df_test.index = range(25000) #reindex the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##process the test data\n",
    "entire_df_test['LENGTH'] = entire_df_test['comment'].apply(lambda x:len(x) - x.count(' '))\n",
    "entire_df_test['punctuation%'] = entire_df_test['comment'].apply(lambda x:count_punc(x))\n",
    "\n",
    "x_count_test = Tfidf_vect.transform(entire_df_test['comment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##csr-matrix the data in order to allow my computer to run it\n",
    "sparse_dataset_test = csr_matrix(x_count_test)\n",
    "s_test = entire_df[['LENGTH','punctuation%']]\n",
    "sparse_dataset_length_punc_test = csr_matrix(s_test)\n",
    "combined_sparse_dataset_test = hstack((sparse_dataset_length_punc_test,sparse_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define the training and testing dataset\n",
    "x_train = combined_sparse_dataset\n",
    "y_train = entire_df['classification']\n",
    "x_test = combined_sparse_dataset_test\n",
    "y_test = entire_df_test['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1644.808613</td>\n",
       "      <td>155.038392</td>\n",
       "      <td>4.127562</td>\n",
       "      <td>0.765638</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'n_estimators': 1000}</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85004</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270.453651</td>\n",
       "      <td>16.140311</td>\n",
       "      <td>1.315086</td>\n",
       "      <td>0.179383</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>0.8288</td>\n",
       "      <td>0.8290</td>\n",
       "      <td>0.8484</td>\n",
       "      <td>0.8252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83392</td>\n",
       "      <td>0.008420</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.327612</td>\n",
       "      <td>1.735813</td>\n",
       "      <td>0.529783</td>\n",
       "      <td>0.078314</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.7408</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73788</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.99395</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.99409</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2    1644.808613    155.038392         4.127562        0.765638   \n",
       "1     270.453651     16.140311         1.315086        0.179383   \n",
       "0      23.327612      1.735813         0.529783        0.078314   \n",
       "\n",
       "  param_n_estimators                  params  split0_test_score  \\\n",
       "2               1000  {'n_estimators': 1000}             0.8456   \n",
       "1                100   {'n_estimators': 100}             0.8288   \n",
       "0                 10    {'n_estimators': 10}             0.7350   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "2             0.8514             0.8566             0.8432       ...          \n",
       "1             0.8290             0.8484             0.8252       ...          \n",
       "0             0.7506             0.7408             0.7258       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "2          0.85004        0.004953                1              1.0000   \n",
       "1          0.83392        0.008420                2              1.0000   \n",
       "0          0.73788        0.008062                3              0.9939   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "2              1.0000             1.00000              1.0000   \n",
       "1              1.0000             1.00000              1.0000   \n",
       "0              0.9937             0.99395              0.9945   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "2              1.0000           1.00000         0.000000  \n",
       "1              1.0000           1.00000         0.000000  \n",
       "0              0.9944           0.99409         0.000307  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Conduct GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param = {\n",
    "    'n_estimators' : [10,100,1000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf,param,cv=5,n_jobs=-1)\n",
    "gs_fit = gs.fit(combined_sparse_dataset,entire_df['classification']) \n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a random forest model\n",
    "rf = RandomForestClassifier(n_estimators = 1000, max_depth = 20)\n",
    "rf_model = rf.fit(x_train,y_train)\n",
    "y_predict = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall,fscore,support = score(y_test,y_predict,pos_label = 1, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :[0.96982575 0.91764261], recall:[0.9128 0.9716],accuracy:0.9422\n"
     ]
    }
   ],
   "source": [
    "print('precision :{}, recall:{},accuracy:{}'.format(precision,recall,(y_predict == y_test).sum()/len(y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.604710</td>\n",
       "      <td>0.178846</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85976</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89300</td>\n",
       "      <td>0.89710</td>\n",
       "      <td>0.89455</td>\n",
       "      <td>0.89215</td>\n",
       "      <td>0.89315</td>\n",
       "      <td>0.89399</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.122630</td>\n",
       "      <td>1.897212</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>0.8490</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85812</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>2</td>\n",
       "      <td>0.93305</td>\n",
       "      <td>0.93745</td>\n",
       "      <td>0.93615</td>\n",
       "      <td>0.93500</td>\n",
       "      <td>0.93450</td>\n",
       "      <td>0.93523</td>\n",
       "      <td>0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.282155</td>\n",
       "      <td>0.350500</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>2</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 2, 'penalty': 'l1'}</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.8484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85692</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92205</td>\n",
       "      <td>0.92605</td>\n",
       "      <td>0.92520</td>\n",
       "      <td>0.92355</td>\n",
       "      <td>0.92240</td>\n",
       "      <td>0.92385</td>\n",
       "      <td>0.001555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.322084</td>\n",
       "      <td>0.669217</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>2</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 2, 'penalty': 'l2'}</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85460</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>4</td>\n",
       "      <td>0.95265</td>\n",
       "      <td>0.95525</td>\n",
       "      <td>0.95505</td>\n",
       "      <td>0.95460</td>\n",
       "      <td>0.95290</td>\n",
       "      <td>0.95409</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.539504</td>\n",
       "      <td>0.801571</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>3</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 3, 'penalty': 'l2'}</td>\n",
       "      <td>0.8654</td>\n",
       "      <td>0.8396</td>\n",
       "      <td>0.8450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85180</td>\n",
       "      <td>0.008922</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96295</td>\n",
       "      <td>0.96940</td>\n",
       "      <td>0.96640</td>\n",
       "      <td>0.96555</td>\n",
       "      <td>0.96450</td>\n",
       "      <td>0.96576</td>\n",
       "      <td>0.002153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       1.604710      0.178846         0.006383        0.001038       1   \n",
       "1       6.122630      1.897212         0.007381        0.000798       1   \n",
       "2       4.282155      0.350500         0.006983        0.000631       2   \n",
       "3       9.322084      0.669217         0.006384        0.000490       2   \n",
       "5       9.539504      0.801571         0.005785        0.000399       3   \n",
       "\n",
       "  param_penalty                     params  split0_test_score  \\\n",
       "0            l1  {'C': 1, 'penalty': 'l1'}             0.8636   \n",
       "1            l2  {'C': 1, 'penalty': 'l2'}             0.8674   \n",
       "2            l1  {'C': 2, 'penalty': 'l1'}             0.8640   \n",
       "3            l2  {'C': 2, 'penalty': 'l2'}             0.8664   \n",
       "5            l2  {'C': 3, 'penalty': 'l2'}             0.8654   \n",
       "\n",
       "   split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "0             0.8576             0.8570       ...                 0.85976   \n",
       "1             0.8490             0.8508       ...                 0.85812   \n",
       "2             0.8514             0.8484       ...                 0.85692   \n",
       "3             0.8444             0.8476       ...                 0.85460   \n",
       "5             0.8396             0.8450       ...                 0.85180   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.003143                1             0.89300             0.89710   \n",
       "1        0.007198                2             0.93305             0.93745   \n",
       "2        0.005969                3             0.92205             0.92605   \n",
       "3        0.007891                4             0.95265             0.95525   \n",
       "5        0.008922                5             0.96295             0.96940   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.89455             0.89215             0.89315   \n",
       "1             0.93615             0.93500             0.93450   \n",
       "2             0.92520             0.92355             0.92240   \n",
       "3             0.95505             0.95460             0.95290   \n",
       "5             0.96640             0.96555             0.96450   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0           0.89399         0.001735  \n",
       "1           0.93523         0.001491  \n",
       "2           0.92385         0.001555  \n",
       "3           0.95409         0.001097  \n",
       "5           0.96576         0.002153  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Conduct GridSearch\n",
    "param_lr = {'C' : [1,2,3,4], 'penalty':['l1','l2']}\n",
    "\n",
    "gs = GridSearchCV(LogisticRegression(),param_lr,cv=5,n_jobs=-1)\n",
    "gs_fit = gs.fit(combined_sparse_dataset,entire_df['classification']) \n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build a Logistic Regression model\n",
    "lr = LogisticRegression(random_state=0,C=1, penalty = 'l1')\n",
    "lr_model = lr.fit(x_train,y_train)\n",
    "y_predict_lr = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall,fscore,support = score(y_test,y_predict_lr,pos_label = 1, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :[0.90791745 0.88649996], recall:[0.88344 0.9104 ],accuracy:0.89692\n"
     ]
    }
   ],
   "source": [
    "print('precision :{}, recall:{},accuracy:{}'.format(precision,recall,(y_predict_lr == y_test).sum()/len(y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\kangh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222184</td>\n",
       "      <td>0.106058</td>\n",
       "      <td>10.583667</td>\n",
       "      <td>3.845678</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.5186</td>\n",
       "      <td>0.5220</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>0.5168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51932</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>1</td>\n",
       "      <td>0.69765</td>\n",
       "      <td>0.69410</td>\n",
       "      <td>0.6973</td>\n",
       "      <td>0.70060</td>\n",
       "      <td>0.7020</td>\n",
       "      <td>0.69833</td>\n",
       "      <td>0.002758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.195569</td>\n",
       "      <td>0.068424</td>\n",
       "      <td>8.259686</td>\n",
       "      <td>1.056118</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.5130</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>0.5228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51708</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>2</td>\n",
       "      <td>0.63620</td>\n",
       "      <td>0.63395</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.63415</td>\n",
       "      <td>0.6353</td>\n",
       "      <td>0.63524</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.222184      0.106058        10.583667        3.845678   \n",
       "1       0.195569      0.068424         8.259686        1.056118   \n",
       "\n",
       "  param_n_neighbors               params  split0_test_score  \\\n",
       "0                 5   {'n_neighbors': 5}             0.5186   \n",
       "1                10  {'n_neighbors': 10}             0.5130   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0             0.5220             0.5240             0.5168       ...          \n",
       "1             0.5176             0.5188             0.5228       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0          0.51932        0.003254                1             0.69765   \n",
       "1          0.51708        0.003678                2             0.63620   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0             0.69410              0.6973             0.70060   \n",
       "1             0.63395              0.6366             0.63415   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0              0.7020           0.69833         0.002758  \n",
       "1              0.6353           0.63524         0.001061  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Conduct GridSearch for KNN\n",
    "param_knn = {\n",
    "    'n_neighbors' : [5,10]\n",
    "}\n",
    "\n",
    "gsknn = GridSearchCV(KNeighborsClassifier(),param_knn,cv=5,n_jobs=2)\n",
    "gs_knn = gsknn.fit(combined_sparse_dataset,entire_df['classification'])\n",
    "pd.DataFrame(gs_knn.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a KNN model\n",
    "KNN_classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "KNN_classifier.fit(x_train, y_train) \n",
    "y_predict_knn = KNN_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :[0.69898893 0.70094059], recall:[0.7024  0.69752],accuracy:0.69996\n"
     ]
    }
   ],
   "source": [
    "precision,recall,fscore,support = score(y_test,y_predict_knn,pos_label = 1, average = None)\n",
    "print('precision :{}, recall:{},accuracy:{}'.format(precision,recall,(y_predict_knn == y_test).sum()/len(y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
